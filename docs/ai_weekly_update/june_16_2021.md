---
layout: default
title: 2021 June 16th
nav_order: -3
parent: AI Weekly Updates
---

## Dynamic Language Models for Continuously Evolving Content

### 개요
- [https://arxiv.org/pdf/2106.06297.pdf](https://arxiv.org/pdf/2106.06297.pdf)
- 세상에는 새로운 entity나 issue가 늘 생기고, 대화 주제의 의미는 점차 변화함
- 모델을 악화시키는 요인: semantic shift, new token
- **변화에 대비하는 방법 제안**
    - 신규 wordpiece를 더하고 덜 쓰이는 wordpiece를 제거하는 dynamic update 
    - incremental training

### 내용
- 문제점 확인
    - vocab shift
        - ![image](https://user-images.githubusercontent.com/6601619/123663458-5ee67e00-d871-11eb-9c28-3e8e72b44398.png)
            - 년도별로 twitter에서 자주 쓰이는(top 40K) wordpiece token. 
            - year 차이가 클수록 어휘 차이가 큼
    - tokenization for new words
        - wordpiece tokenizer는 unseen word의 OOV를 줄여주긴 하지만, 그 semantic을 보장하진 못함
    - token semantic shift
        - 2014년과 2017년에 동시에 등장한 빈번한 단어 1000개에 대하여, contextual words의 vocab shift를 확인해보니 큰 차이가 남 
- Dynamic Updates to Model Vocabulary
    - 가장 빈번한 신규 wordpiece를 추가하고, 가장 덜 사용되는 기존 wordpiece를 제거
    - vocab size 유지, vocab 최신화
- Effective Sampling
    - incremental training을 위한 데이터 선정 세가지 방법
    - 1 . token embedding shift: 학습 후 weight 변화가 큰 토큰이 있는 문장 선택
        - 학습 iteration마다 데이터 샘플링
        - 학습 후 embedding 변화가 가장 큰 token들을 선택
        - (α * cosine distance + (1-α) * 데이터길이)를 weight로, 다음 iteration의 데이터를 weighted random sampling
            - 짧은데이터는 variance 심함
    - 2 . sentence embedding shift: 문장의 embedding 변화가 큰 문장 선택
        - [CLS]의 embedding 변화가 큰 문장에 weight를 줌
        - (α * cosine distance + (1-α) * 데이터길이)
    - 3 . token MLM loss
        - token에 대한 MLM loss를 weight로 sampling
- 학습 트리거  
    - token 마다 MLM loss를 기억
    - token의 MLM loss가 평소보다 매우 커지게 하는 데이터가 들어오면 샘플링 + 학습 과정 진행
        - 신규 데이터들 중 어려운 데이터가 있을때만 trigger
   
         
-----------

## Improving Language Model Behavior by Training on a Curated Dataset

### 개요
- [https://www.openai.com/blog/improving-language-model-behavior/](https://www.openai.com/blog/improving-language-model-behavior/)
- LM의 예측 불가능한 위험발언이 사회적으로 문제가 되기도 한다. **선별된 작은 데이터셋으로 finetune 해서 모델의 이상행동을 개선시킬 수 있다.**
- 매 iteration마다 평가시 발견된 단점을 보완하는 학습 데이터를 추가
- 모델 크기가 증가할수록 효과가 좋았다

### 내용
- ![image](https://user-images.githubusercontent.com/6601619/123304369-da86b900-d559-11eb-81f2-3c97d89fd62c.png)
- step1: topic selection
    - 민감한 8개의 토픽을 선정하였다
    - violence, health, human characteristics, injustice, political opinion, relationship, sexual activity, terror
- step2: desired behavior description
    - 각 토픽에 대하여 기준이 될 "올바른 행동"을 정의
    - ![image](https://user-images.githubusercontent.com/6601619/123305126-b8416b00-d55a-11eb-9a2f-7bb816251a5b.png)
- step3: dataset prompt creation
    - 다양한 주제의 질문 70문장과, step1에서 정한 토픽들 중 낮은 성능을 보인 토픽의 질문 10문장을 작성
- step4: dataset completion creation
    - 질문 문장마다 step2를 준수하는 답변을 작성
    - 작성 가이드라인을 두어, 비슷한 퀄리티의 답변들이 작성되도록 함
- step5: finetune
- step6: evaluation
    - validation and test sets 
        - step1에서 정한 토픽들에 대해 5개의 예시를 생성
        - 예시마다 0.7 temperture로 3개씩 답변 생성
        - toxicity scoring + human evaluation
    - control dataset
        - 높은 퀄리티의 데이터로 finetune 하는 것 자체가 성능향상을 주었을수도 있으므로, 대조군으로 쓸 데이터셋 
        - 책과 위키에서 랜덤하게 100개의 snippet을 발췌
    - 정량지표
        - toxicity scoring
            - [Perspective](https://www.perspectiveapi.com/how-it-works)라는 모델을 사용. (욕설댓글 탐지 모델)
        - human eval
            - step2에서 정의한 내용을 얼마나 준수하는지 사람이 평가
            - 세명의 평가자
    - 정성지표
        - base 모델, control dataset 사용한 모델, 제안모델로 gender, religion, race에 대하여 각 800개의 설명문을 생성하도록 함
        - 모델끼리 카테고리별 최빈 단어를 비교
        - 각 주제에 대하여 모델의 bias를 확인 할 수 있다.
- step7: iterate
    - 앞 내용들을 반복. step2, 3, 4 중에 한곳에서 재시작한다.

-----------

## Does Knowledge Distillation Really Work?

### 개요
- [https://arxiv.org/pdf/2106.05945.pdf](https://arxiv.org/pdf/2106.05945.pdf)
- large model이나 ensemble model을 teacher로 하는 KD
- distillation이 student generalization에 도움이 되지만, student와 teacher간 pred distribution이 의외로 일치하지 않는 경우가 많음 (심지어 student와 teacher의 capacity가 똑같음에도)
- **student, teacher 불일치가 발생하는 이유를 확인**
### 내용
- ![image](https://user-images.githubusercontent.com/6601619/123137403-e0fc2e80-d48e-11eb-8ef7-a43780171f2f.png)
    - teacher와 student의 capacity가 같은 경우, 데이터가 늘어남에 따라 fidelity가 증가하지만 student acc가 감소함
        - student outperform teacher 
    - teacher의 capcacity가 더 큰 경우, 데이터가 늘어남에 따라 fidelity가 증가하고 student acc는 살짝 증가함 
- Why care about fidelity?
    - ensemble이나 large model을 teacher로 사용할 경우, student fidelity를 높이는 것이 student-teacher 사이 격차를 줄이는것에 도움이 되었음
        - ![image](https://user-images.githubusercontent.com/6601619/123139328-1144cc80-d491-11eb-8e37-ae8f20b74522.png) 
             - ensemble 수를 늘릴수록 fidelity가 높아젔으나 student acc는 어느순간 saturated
    - large model은 데이터에서 우리가 예상하지 못한 규칙을 발견하기도 함
        - 이 발견을 잘 전달하는것이 중요함
### 결론
- ![image](https://user-images.githubusercontent.com/6601619/123140312-19e9d280-d492-11eb-91ee-985962b408d3.png)

