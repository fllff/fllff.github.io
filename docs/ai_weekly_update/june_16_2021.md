---
layout: default
title: 2021 June 16th
nav_order: -3
parent: AI Weekly Updates
---

## Improving Language Model Behavior by Training on a Curated Dataset

### 개요
- [https://www.openai.com/blog/improving-language-model-behavior/](https://www.openai.com/blog/improving-language-model-behavior/)
- LM의 예측 불가능한 위험발언이 사회적으로 문제가 되기도 한다. **선별된 작은 데이터셋으로 finetune 해서 모델의 이상행동을 개선시킬 수 있다.**
- 매 iteration마다 평가시 발견된 단점을 보완하는 학습 데이터를 추가
- 모델 크기가 증가할수록 효과가 좋았다

### 내용
- ![image](https://user-images.githubusercontent.com/6601619/123304369-da86b900-d559-11eb-81f2-3c97d89fd62c.png)
- step1: topic selection
    - 민감한 8개의 토픽을 선정하였다
    - violence, health, human characteristics, injustice, political opinion, relationship, sexual activity, terror
- step2: desired behavior description
    - 각 토픽에 대하여 기준이 될 "올바른 행동"을 정의
    - ![image](https://user-images.githubusercontent.com/6601619/123305126-b8416b00-d55a-11eb-9a2f-7bb816251a5b.png)
- step3: dataset prompt creation
    - 다양한 주제의 질문 70문장과, step1에서 정한 토픽들 중 낮은 성능을 보인 토픽의 질문 10문장을 작성
- step4: dataset completion creation
    - 질문 문장마다 step2를 준수하는 답변을 작성
    - 작성 가이드라인을 두어, 비슷한 퀄리티의 답변들이 작성되도록 함
- step5: finetune
- step6: evaluation
    - validation and test sets 
        - step1에서 정한 토픽들에 대해 5개의 예시를 생성
        - 예시마다 0.7 temperture로 3개씩 답변 생성
        - toxicity scoring + human evaluation
    - control dataset
        - 높은 퀄리티의 데이터로 finetune 하는 것 자체가 성능향상을 주었을수도 있으므로, 대조군으로 쓸 데이터셋 
        - 책과 위키에서 랜덤하게 100개의 snippet을 발췌
    - 정량지표
        - toxicity scoring
            - [Perspective](https://www.perspectiveapi.com/how-it-works)라는 모델을 사용. (욕설댓글 탐지 모델)
        - human eval
            - step2에서 정의한 내용을 얼마나 준수하는지 사람이 평가
            - 세명의 평가자
    - 정성지표
        - base 모델, control dataset 사용한 모델, 제안모델로 gender, religion, race에 대하여 각 800개의 설명문을 생성하도록 함
        - 모델끼리 카테고리별 최빈 단어를 비교
        - 각 주제에 대하여 모델의 bias를 확인 할 수 있다.
- step7: iterate
    - 앞 내용들을 반복. step2, 3, 4 중에 한곳에서 재시작한다.


## Does Knowledge Distillation Really Work?

### 개요
- [https://arxiv.org/pdf/2106.05945.pdf](https://arxiv.org/pdf/2106.05945.pdf)
- large model이나 ensemble model을 teacher로 하는 KD
- distillation이 student generalization에 도움이 되지만, student와 teacher간 pred distribution이 의외로 일치하지 않는 경우가 많음 (심지어 student와 teacher의 capacity가 똑같음에도)
- **student, teacher 불일치가 발생하는 이유를 확인**
### 내용
- ![image](https://user-images.githubusercontent.com/6601619/123137403-e0fc2e80-d48e-11eb-8ef7-a43780171f2f.png)
    - teacher와 student의 capacity가 같은 경우, 데이터가 늘어남에 따라 fidelity가 증가하지만 student acc가 감소함
        - student outperform teacher 
    - teacher의 capcacity가 더 큰 경우, 데이터가 늘어남에 따라 fidelity가 증가하고 student acc는 살짝 증가함 
- Why care about fidelity?
    - ensemble이나 large model을 teacher로 사용할 경우, student fidelity를 높이는 것이 student-teacher 사이 격차를 줄이는것에 도움이 되었음
        - ![image](https://user-images.githubusercontent.com/6601619/123139328-1144cc80-d491-11eb-8e37-ae8f20b74522.png) 
             - ensemble 수를 늘릴수록 fidelity가 높아젔으나 student acc는 어느순간 saturated
    - large model은 데이터에서 우리가 예상하지 못한 규칙을 발견하기도 함
        - 이 발견을 잘 전달하는것이 중요함
### 결론
- ![image](https://user-images.githubusercontent.com/6601619/123140312-19e9d280-d492-11eb-91ee-985962b408d3.png)

