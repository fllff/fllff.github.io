---
layout: default
title: 2021 June 16th
nav_order: -3
parent: AI Weekly Updates
---

## Improving Language Model Behavior by Training on a Curated Dataset

### 개요
- [https://www.openai.com/blog/improving-language-model-behavior/](https://www.openai.com/blog/improving-language-model-behavior/)
- LM의 예측 불가능한 위험발언이 사회적으로 문제가 되기도 한다. **선별된 작은 데이터셋으로 finetune 해서 모델의 이상행동을 개선시킬 수 있다.**

### 내용


## Does Knowledge Distillation Really Work?

### 개요
- [https://arxiv.org/pdf/2106.05945.pdf](https://arxiv.org/pdf/2106.05945.pdf)
- large model이나 ensemble model을 teacher로 하는 KD
- distillation이 student generalization에 도움이 되지만, student와 teacher간 pred distribution이 의외로 일치하지 않는 경우가 많음 (심지어 student와 teacher의 capacity가 똑같음에도)
- **student, teacher 불일치가 발생하는 이유를 확인**
### 내용
- ![image](https://user-images.githubusercontent.com/6601619/123137403-e0fc2e80-d48e-11eb-8ef7-a43780171f2f.png)
    - teacher와 student의 capacity가 같은 경우, 데이터가 늘어남에 따라 fidelity가 증가하지만 student acc가 감소함
        - student outperform teacher 
    - teacher의 capcacity가 더 큰 경우, 데이터가 늘어남에 따라 fidelity가 증가하고 student acc는 살짝 증가함 
- Why care about fidelity?
    - ensemble이나 large model을 teacher로 사용할 경우, student fidelity를 높이는 것이 student-teacher 사이 격차를 줄이는것에 도움이 되었음
        - ![image](https://user-images.githubusercontent.com/6601619/123139328-1144cc80-d491-11eb-8e37-ae8f20b74522.png) 
             - ensemble 수를 늘릴수록 fidelity가 높아젔으나 student acc는 어느순간 saturated
    - large model은 데이터에서 우리가 예상하지 못한 규칙을 발견하기도 함
        - 이 발견을 잘 전달하는것이 중요함
### 결론
- ![image](https://user-images.githubusercontent.com/6601619/123140312-19e9d280-d492-11eb-91ee-985962b408d3.png)

